import streamlit as st
import pandas as pd
import requests
import urllib3
from datetime import datetime
import altair as alt

# 1. åŸºç¤é˜²è­·èˆ‡ç’°å¢ƒè¨­å®š (è™•ç† SSL æ†‘è­‰å•é¡Œ)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="é™æ§ç„¡äººæ©Ÿè³‡å®‰æª¢æ¸¬åˆæ ¼æ¸…å–® (ä¸­æšè³‡è¨Šå½™æ•´)", page_icon="ğŸ›¡ï¸", layout="wide")

# æ”¿åºœè³‡æ–™é–‹æ”¾å¹³å°ä¾†æº
JSON_URL = "https://quality.data.gov.tw/dq_download_json.php?nid=174663&md5_url=12c13680f07f84091e72fcc351447baf"
# ç´…è‰²ä¾›æ‡‰éˆå“ç‰Œæ¸…å–® (é¿å‘ç”¨)
RED_LIST = ["DJI", "å¤§ç–†", "Autel", "é“é€š", "Hubsan", "FIMI", "å“ˆåšæ£®"]

# 2. å¼·åŒ–æ—¥æœŸè½‰æ› (è™•ç†æ°‘åœ‹å¹´æ ¼å¼)
def safe_roc_to_datetime(roc_val):
    try:
        s = str(roc_val).strip()
        if len(s) < 6: return None
        year = int(s[:-4]) + 1911
        month = int(s[-4:-2])
        day = int(s[-2:])
        return datetime(year, month, day)
    except:
        return None

@st.cache_data(ttl=3600)
def load_and_fix_data():
    try:
        response = requests.get(JSON_URL, verify=False, timeout=15)
        df = pd.DataFrame(response.json())
        df.columns = [col.strip() for col in df.columns]
        
        # æ¬„ä½è‡ªå‹•æ˜ å°„ (å°é½Šæ”¿åºœ API çš„ Key)
        mapping = {"ç”³è«‹å–®ä½": "å» å•†åç¨±", "å ±å‘Šæ—¥æœŸ": "æª¢æ¸¬æ—¥æœŸ"}
        for old_c, new_c in mapping.items():
            if old_c in df.columns: df[new_c] = df[old_c]
        
        # è£œé½Šå¿…è¦æ¬„ä½
        for col in ['å» å•†åç¨±', 'å» ç‰Œ', 'å‹å¼', 'æœ‰æ•ˆæ—¥æœŸ']:
            if col not in df.columns: df[col] = "ä¸è©³"

        # æ—¥æœŸé‹ç®—
        today = datetime.now()
        df['è¥¿å…ƒæ—¥æœŸ'] = df['æœ‰æ•ˆæ—¥æœŸ'].apply(safe_roc_to_datetime)
        df['å‰©é¤˜å¤©æ•¸'] = df['è¥¿å…ƒæ—¥æœŸ'].apply(lambda x: (x - today).days if x else 9999)
        
        def get_status(days):
            if days == 9999: return "ç„¡æ•ˆæœŸè³‡æ–™"
            if days < 0: return "ğŸš« å·²éæœŸ"
            if days < 90: return "âš ï¸ é è­¦ (90å¤©å…§)"
            return "âœ… å®‰å…¨"
        df['è³‡å®‰ç‹€æ…‹'] = df['å‰©é¤˜å¤©æ•¸'].apply(get_status)
        
        return df
    except Exception as e:
        st.error(f"è³‡æ–™ä¾†æºé€£ç·šå¤±æ•—: {e}")
        return pd.DataFrame()

# 3. ä¸»ä»‹é¢é‚è¼¯
def main():
    # æ›´æ–°æ¨™é¡Œï¼šæ”¹ç‚ºä¸­æšè³‡è¨Šå½™æ•´ç‰ˆæœ¬
    st.title("ğŸ›¡ï¸ é™æ§ç„¡äººæ©Ÿè³‡å®‰æª¢æ¸¬åˆæ ¼æ¸…å–® (ä¸­æšè³‡è¨Šå½™æ•´)")
    
    if 'search_input' not in st.session_state:
        st.session_state.search_input = ""

    df = load_and_fix_data()
    if df.empty: return

    # --- å·¦å´é¸å–®ï¼šæ‡¶äººå¿«é€Ÿæ´å¯Ÿ ---
    st.sidebar.header("âš¡ æ‡¶äººå¿«é€Ÿæ´å¯Ÿ")
    
    quick_mode = st.sidebar.radio(
        "é¸æ“‡å¿«æŸ¥æ¨¡å¼ï¼š",
        ["å…¨éƒ¨æ¸…å–®", "âœ… éæ•æ„Ÿä¾›æ‡‰éˆ (æœ¬åœŸ)", "ğŸš« æ•æ„Ÿä¾›æ‡‰éˆ (é¿å‘)", "ğŸ† é«˜è³‡å®‰ç­‰ç´š (Level 3)", "â³ æ•ˆæœŸé è­¦æ¨¡å¼"],
        key="quick_mode"
    )
    
    if st.sidebar.button("ğŸ§¹ æ¸…é™¤æœå°‹æ¢ä»¶"):
        st.session_state.search_input = ""
        st.rerun()

    st.sidebar.divider()
    st.sidebar.metric("åˆæ ¼ç”¢å“ç¸½æ•¸", len(df))
    
    # --- æ ¸å¿ƒç¯©é¸é‚è¼¯ ---
    f_df = df.copy()
    red_pattern = "|".join(RED_LIST)
    
    if quick_mode == "âœ… éæ•æ„Ÿä¾›æ‡‰éˆ (æœ¬åœŸ)":
        f_df = f_df[~f_df["å» ç‰Œ"].str.contains(red_pattern, case=False, na=False)]
    elif quick_mode == "ğŸš« æ•æ„Ÿä¾›æ‡‰éˆ (é¿å‘)":
        f_df = f_df[f_df["å» ç‰Œ"].str.contains(red_pattern, case=False, na=False)]
        st.error("ğŸš¨ è­¦å‘Šï¼šç›®å‰é¡¯ç¤ºç‚ºæ•æ„Ÿä¾›æ‡‰éˆå“ç‰Œï¼Œæ¡è³¼å‰è«‹ç¢ºèªåˆè¦æ€§ã€‚")
    elif quick_mode == "ğŸ† é«˜è³‡å®‰ç­‰ç´š (Level 3)":
        f_df = f_df[f_df.astype(str).apply(lambda x: x.str.contains("3", case=False)).any(axis=1)]
    elif quick_mode == "â³ æ•ˆæœŸé è­¦æ¨¡å¼":
        f_df = f_df[f_df['å‰©é¤˜å¤©æ•¸'] < 180].sort_values("å‰©é¤˜å¤©æ•¸")

    # é—œéµå­—æœå°‹é€£å‹•
    st.subheader(f"ğŸ” ç›®å‰æ¨¡å¼ï¼š{quick_mode}")
    keyword = st.text_input("æœå°‹å‹è™Ÿæˆ–å» å•†åç¨±", value=st.session_state.search_input, key="main_search")
    st.session_state.search_input = keyword

    if keyword:
        keyword_df = f_df[f_df.astype(str).apply(lambda x: x.str.contains(keyword, case=False)).any(axis=1)]
        if keyword_df.empty:
            st.warning(f"ğŸ’¡ åœ¨ç›®å‰çš„éæ¿¾æ¢ä»¶ä¸‹æ‰¾ä¸åˆ°ã€{keyword}ã€ã€‚")
        else:
            f_df = keyword_df

    # --- åŠŸèƒ½åˆ†é  ---
    tab1, tab2, tab3 = st.tabs(["ğŸ” è¨­å‚™æ¸…å–®", "â³ èªè­‰æ•ˆæœŸ", "ğŸ“Š æ•¸æ“šçµ±è¨ˆ"])

    with tab1:
        st.dataframe(f_df, use_container_width=True)

    with tab2:
        st.subheader("è³‡å®‰èªè­‰å€’æ•¸èˆ‡ç‹€æ…‹")
        target_cols = ['å» å•†åç¨±', 'å» ç‰Œ', 'å‹å¼', 'æœ‰æ•ˆæ—¥æœŸ', 'å‰©é¤˜å¤©æ•¸', 'è³‡å®‰ç‹€æ…‹']
        avail_cols = [c for c in target_cols if c in f_df.columns]
        st.dataframe(f_df[avail_cols].sort_values("å‰©é¤˜å¤©æ•¸"), use_container_width=True)

    with tab3:
        st.subheader("ç”¢æ¥­åˆè¦åˆ†æ")
        c1, c2 = st.columns(2)
        with c1:
            st.write("**ä¸»è¦é€æ¸¬å» å•† (Top 10)**")
            counts = df['å» å•†åç¨±'].value_counts().reset_index().head(10)
            st.bar_chart(counts, x='å» å•†åç¨±', y='count')
        with c2:
            st.write("**è³‡å®‰ç‹€æ…‹åˆ†ä½ˆ (å…¨éƒ¨è³‡æ–™)**")
            status_df = df['è³‡å®‰ç‹€æ…‹'].value_counts().reset_index()
            pie = alt.Chart(status_df).mark_arc().encode(theta='count', color='è³‡å®‰ç‹€æ…‹')
            st.altair_chart(pie, use_container_width=True)

    st.divider()
    st.caption("ç”± Bear Magpie Intelligence å®‰å…¨åœ˜éšŠç¶­è­· | æ•¸æ“šä¾†æºï¼šæ”¿åºœé–‹æ”¾è³‡æ–™å¹³å°")

if __name__ == "__main__":
    main()
